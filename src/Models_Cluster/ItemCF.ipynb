{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389311b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b29d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster_folder_path = \"./cluster_data/\"\n",
    "\n",
    "# def find_nearest_neighbor(encoded_try_list: np.ndarray, clustered_user_df: pd.DataFrame):\n",
    "#     # Ensure the clustered_user_df has a 'user_id' column and encoded category columns.\n",
    "#     if 'user_id' not in clustered_user_df.columns:\n",
    "#         raise ValueError(\"clustered_user_df must include a 'user_id' column.\")\n",
    "\n",
    "#     # Select the encoded features from clustered_user_df; assume all columns except 'user_id'\n",
    "#     features = clustered_user_df.drop(columns=['user_id', 'cluster']).values\n",
    "\n",
    "#     # Create the NearestNeighbors model using Jaccard metric\n",
    "#     nn_model = NearestNeighbors(n_neighbors=1, metric='jaccard')\n",
    "#     nn_model.fit(features)\n",
    "\n",
    "#     # Query the model to get nearest neighbor index and distance\n",
    "#     distances, indices = nn_model.kneighbors(encoded_try_list)\n",
    "\n",
    "#     # Create a list to hold results\n",
    "#     results = []\n",
    "#     for idx, (dist, ind) in enumerate(zip(distances, indices)):\n",
    "#         # Get the corresponding user_id from clustered_user_df using the index\n",
    "#         nearest_cluster_id = clustered_user_df.iloc[ind[0]]['cluster']\n",
    "#         results.append({\n",
    "#             'input_index': int(idx),\n",
    "#             'nearest_cluster_id': int(nearest_cluster_id),\n",
    "#             # 'distance': dist[0]\n",
    "#         })\n",
    "#     return results\n",
    "\n",
    "# def find_cluster_id(categories: list):\n",
    "#     clustered_user_df = pd.read_pickle(Cluster_folder_path + 'clustered_user_df.pkl')\n",
    "\n",
    "#     if not isinstance(categories, list) or not all(isinstance(i, list) for i in categories):\n",
    "#         categories = [categories]\n",
    "#     categories = np.array(categories)\n",
    "\n",
    "#     with open(Cluster_folder_path + 'users_categories_encoder.pkl', 'rb') as f:\n",
    "#         user_category_encoder = pickle.load(f)\n",
    "#         f.close()\n",
    "\n",
    "#     encoded_try_list = user_category_encoder.transform(categories)\n",
    "\n",
    "#     results = find_nearest_neighbor(encoded_try_list,clustered_user_df)\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32522fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cluster_utils import *\n",
    "from scipy.sparse import csr_matrix\n",
    "from sparse_dot_topn import sp_matmul_topn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f7b066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 980418 rows from review table.\n"
     ]
    }
   ],
   "source": [
    "# Define the database folder path and file names\n",
    "db_folder = '../../data/processed_data/yelp_data/'\n",
    "data_files = ['review']\n",
    "\n",
    "# Load data into a dictionary\n",
    "yelp_data = load_data_from_db(db_folder, data_files)\n",
    "\n",
    "# Check loaded data\n",
    "for table, df in yelp_data.items():\n",
    "    print(f\"Loaded {len(df)} rows from {table} table.\")\n",
    "    \n",
    "df_review = yelp_data[\"review\"][[\"user_id\", \"business_id\", \"stars\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7d1676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yueny\\AppData\\Local\\Temp\\ipykernel_8940\\1249627618.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_review['cluster'] = df_review['user_id'].map(user_cluster)\n"
     ]
    }
   ],
   "source": [
    "# Load cluster data and map to reviews (your existing code)\n",
    "df_cluster = pd.read_excel(\"../data_processing/clustered_users.xlsx\")\n",
    "user_cluster = df_cluster.set_index('user_id')['cluster'].to_dict()\n",
    "df_review['cluster'] = df_review['user_id'].map(user_cluster)\n",
    "df_review = df_review.dropna(subset=['cluster'])\n",
    "\n",
    "# Calculate the global mean of stars\n",
    "global_mean = df_review['stars'].mean()\n",
    "\n",
    "# Choose a constant C (e.g., 5; adjust based on your data)\n",
    "C = 5\n",
    "\n",
    "# Group by business_id and cluster, calculate sum and count of stars\n",
    "df_cluster_review = df_review.groupby(['business_id', 'cluster'])['stars'].agg(['sum', 'count']).reset_index()\n",
    "\n",
    "# Calculate the weighted score\n",
    "df_cluster_review['score'] = (df_cluster_review['sum'] + C * global_mean) / (df_cluster_review['count'] + C)\n",
    "\n",
    "cluster_business = df_cluster_review.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44baa19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574325</th>\n",
       "      <td>mtvT7uRey3F395STFRM1Tg</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>20</td>\n",
       "      <td>4.731418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150966</th>\n",
       "      <td>C6YaSrMAzy3jJqinlFVudw</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4.708063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39331</th>\n",
       "      <td>2KIDQyTh-HzLxOUEDqtDBg</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>27</td>\n",
       "      <td>4.696420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504036</th>\n",
       "      <td>gfLsBY-xsNE9-ktiTvTvGA</td>\n",
       "      <td>1356.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4.694793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438558</th>\n",
       "      <td>atZ_olNKXOG4rEr6mccN8g</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>23</td>\n",
       "      <td>4.688766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569134</th>\n",
       "      <td>mRTRMo-M0B_9fMOnzzMtsQ</td>\n",
       "      <td>978.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.047574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569136</th>\n",
       "      <td>mRTRMo-M0B_9fMOnzzMtsQ</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.047574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569114</th>\n",
       "      <td>mRGoD7FolIbmR5ANRU3SCw</td>\n",
       "      <td>167.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.047574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569103</th>\n",
       "      <td>mRALAZduUGa_QBAyxQ89HQ</td>\n",
       "      <td>1084.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.047574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569104</th>\n",
       "      <td>mRALAZduUGa_QBAyxQ89HQ</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.047574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  cluster    sum  count     score\n",
       "574325  mtvT7uRey3F395STFRM1Tg   1090.0   99.0     20  4.731418\n",
       "150966  C6YaSrMAzy3jJqinlFVudw   1830.0   89.0     18  4.708063\n",
       "39331   2KIDQyTh-HzLxOUEDqtDBg   1090.0  131.0     27  4.696420\n",
       "504036  gfLsBY-xsNE9-ktiTvTvGA   1356.0   84.0     17  4.694793\n",
       "438558  atZ_olNKXOG4rEr6mccN8g   1090.0  112.0     23  4.688766\n",
       "...                        ...      ...    ...    ...       ...\n",
       "569134  mRTRMo-M0B_9fMOnzzMtsQ    978.0    5.0      1  4.047574\n",
       "569136  mRTRMo-M0B_9fMOnzzMtsQ   1589.0    5.0      1  4.047574\n",
       "569114  mRGoD7FolIbmR5ANRU3SCw    167.0    5.0      1  4.047574\n",
       "569103  mRALAZduUGa_QBAyxQ89HQ   1084.0    5.0      1  4.047574\n",
       "569104  mRALAZduUGa_QBAyxQ89HQ   1090.0    5.0      1  4.047574\n",
       "\n",
       "[100000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by score\n",
    "sorted_cluster_business = cluster_business.sort_values(by='score', ascending=False)\n",
    "sorted_cluster_business[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5327b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_business(cluster_business):\n",
    "    cluster_mapping = {clus: idx for idx, clus in enumerate(cluster_business['cluster'].unique())}\n",
    "    business_mapping = {biz: idx for idx, biz in enumerate(cluster_business['business_id'].unique())}    \n",
    "    return cluster_mapping, business_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c83bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_mapping, business_mapping = get_cluster_business(cluster_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "138dc1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(cluster_business, test_size=0.2, random_state=42)\n",
    "\n",
    "cluster_business = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "756641c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map user_id and business_id to numerical indices\n",
    "cluster_business['cluster_idx'] = cluster_business['cluster'].map(cluster_mapping)\n",
    "cluster_business['business_idx'] = cluster_business['business_id'].map(business_mapping)\n",
    "\n",
    "# Creating the sparse user-item interaction matrix using weighted_stars\n",
    "user_item_sparse = csr_matrix(\n",
    "    (cluster_business['score'], (cluster_business['cluster_idx'], cluster_business['business_idx'])),\n",
    "    shape=(len(cluster_mapping), len(business_mapping))\n",
    ")\n",
    "\n",
    "# Replace NaN values in the sparse matrix\n",
    "user_item_sparse.data = np.nan_to_num(user_item_sparse.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14957fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cosine_similarity_topn(A, top_n, threshold=0):\n",
    "    C = sp_matmul_topn(A.T, A.T, top_n=top_n, threshold=threshold, n_threads=4, sort=True)\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9a936c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute item similarity\n",
    "item_similarity_sparse = sparse_cosine_similarity_topn(user_item_sparse, top_n=100, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc5b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_db(conn):\n",
    "    \"\"\"Apply SQLite performance optimizations.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.executescript('''\n",
    "        PRAGMA synchronous = OFF;\n",
    "        PRAGMA journal_mode = MEMORY;\n",
    "        PRAGMA temp_store = MEMORY;\n",
    "        PRAGMA cache_size = 1000000;\n",
    "    ''')\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def insert_cluster_item(cluster_business, conn, batch_size=50000):\n",
    "    \"\"\"Optimized batch insert for cluster-item interactions.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('BEGIN TRANSACTION')\n",
    "\n",
    "    total_records = len(cluster_business)\n",
    "    # sort the score and filter the top 50 for each cluster\n",
    "    cluster_business = cluster_business.sort_values(by='score', ascending=False).groupby('cluster').head(50)\n",
    "    data = cluster_business[['cluster', 'business_id', 'score']].values.tolist()\n",
    "\n",
    "    for i in range(0, total_records, batch_size):\n",
    "        batch = data[i:i + batch_size]\n",
    "        cursor.executemany('''INSERT OR IGNORE INTO cluster_item_index (cluster, business_id, score)\n",
    "                              VALUES (?, ?, ?)''', batch)\n",
    "\n",
    "        if i % (batch_size * 5) == 0:  # Commit every 5 batches\n",
    "            conn.commit()\n",
    "            print(f\"Inserted {i + len(batch)} / {total_records} cluster-item records.\")\n",
    "\n",
    "    conn.commit()  # Final commit\n",
    "    print(f\"Total {total_records} cluster-item records inserted.\")\n",
    "\n",
    "    \n",
    "def insert_item_vectors(item_similarity_sparse, business_mapping, conn, batch_size=5000, progress_interval=50000):\n",
    "    \"\"\"Optimized batch insert for item similarity vectors.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('BEGIN TRANSACTION')\n",
    "\n",
    "    total_inserted = 0\n",
    "    batch = []\n",
    "    business_keys = list(business_mapping.keys())  # Convert keys to list for faster indexing\n",
    "\n",
    "    for row_idx in range(item_similarity_sparse.shape[0]):\n",
    "        row_vector = item_similarity_sparse.getrow(row_idx)\n",
    "        row_indices = row_vector.indices\n",
    "        row_data = row_vector.data\n",
    "\n",
    "        serialized_row = pickle.dumps((row_indices, row_data))\n",
    "        item_id = business_keys[row_idx]  # Faster lookup\n",
    "\n",
    "        batch.append((item_id, serialized_row))\n",
    "\n",
    "        if len(batch) >= batch_size:\n",
    "            cursor.executemany('''INSERT OR REPLACE INTO item_item_similarity (item_id, similarity_vector)\n",
    "                                  VALUES (?, ?)''', batch)\n",
    "            total_inserted += len(batch)\n",
    "\n",
    "            if total_inserted % progress_interval == 0:\n",
    "                print(f\"Inserted {total_inserted} item vectors...\")\n",
    "\n",
    "            batch = []\n",
    "\n",
    "    if batch:  # Insert remaining records\n",
    "        cursor.executemany('''INSERT OR REPLACE INTO item_item_similarity (item_id, similarity_vector)\n",
    "                              VALUES (?, ?)''', batch)\n",
    "        total_inserted += len(batch)\n",
    "\n",
    "    conn.commit()\n",
    "    print(f\"Total {total_inserted} item vectors inserted.\")\n",
    "\n",
    "\n",
    "def insert_mappings(business_mapping, conn, batch_size=50000):\n",
    "    \"\"\"Optimized batch insert for business mappings.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('BEGIN TRANSACTION')\n",
    "\n",
    "    data = list(business_mapping.items())\n",
    "    total_records = len(data)\n",
    "\n",
    "    for i in range(0, total_records, batch_size):\n",
    "        batch = data[i:i + batch_size]\n",
    "        cursor.executemany('''INSERT OR REPLACE INTO business_mapping (business_id, business_idx)\n",
    "                              VALUES (?, ?)''', batch)\n",
    "\n",
    "        if i % (batch_size * 5) == 0:  # Commit every 5 batches\n",
    "            conn.commit()\n",
    "            print(f\"Inserted {i + len(batch)} / {total_records} business mappings.\")\n",
    "\n",
    "    conn.commit()\n",
    "    print(f\"Total {total_records} business mappings inserted.\")\n",
    "    \n",
    "    \n",
    "# function to insert df_cluster to the table user_cluster_mapping\n",
    "def insert_user_cluster_mapping(df_cluster, conn, batch_size=50000):\n",
    "    \"\"\"Optimized batch insert for user cluster mapping.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('BEGIN TRANSACTION')\n",
    "\n",
    "    total_records = len(df_cluster)\n",
    "    data = df_cluster[['user_id', 'cluster']].values.tolist()\n",
    "\n",
    "    for i in range(0, total_records, batch_size):\n",
    "        batch = data[i:i + batch_size]\n",
    "        cursor.executemany('''INSERT OR IGNORE INTO user_cluster_mapping (user_id, cluster)\n",
    "                              VALUES (?, ?)''', batch)\n",
    "\n",
    "        if i % (batch_size * 5) == 0:  # Commit every 5 batches\n",
    "            conn.commit()\n",
    "            print(f\"Inserted {i + len(batch)} / {total_records} user cluster mappings.\")\n",
    "\n",
    "    conn.commit()  # Final commit\n",
    "    print(f\"Total {total_records} user cluster mappings inserted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5fcc951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQLite (this will create a file-based database)\n",
    "db_path = './cluster_data/yelp_ClusterItemCF.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "optimize_db(conn)\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS user_cluster_mapping (\n",
    "    user_id TEXT PRIMARY KEY,\n",
    "    cluster INTEGER\n",
    ")''')\n",
    "\n",
    "# Create tables for cluster-item and item-item indexes\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS cluster_item_index (\n",
    "    cluster INTEGER,\n",
    "    business_id TEXT,\n",
    "    score REAL,\n",
    "    PRIMARY KEY (cluster, business_id)\n",
    ")''')\n",
    "\n",
    "cursor.execute('''CREATE INDEX IF NOT EXISTS idx_cluster_item ON cluster_item_index(cluster, business_id)''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS item_item_similarity (\n",
    "    item_id TEXT PRIMARY KEY,\n",
    "    similarity_vector BLOB\n",
    ")''')\n",
    "\n",
    "cursor.execute('''CREATE INDEX IF NOT EXISTS idx_item_similarity ON item_item_similarity(item_id)''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS business_mapping (\n",
    "    business_id TEXT PRIMARY KEY,\n",
    "    business_idx INTEGER\n",
    ")''')\n",
    "\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30b8acc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 50000 / 577061 cluster-item records.\n",
      "Inserted 250000 / 577061 cluster-item records.\n",
      "Inserted 500000 / 577061 cluster-item records.\n",
      "Total 577061 cluster-item records inserted.\n",
      "Inserted 50000 item vectors...\n",
      "Total 70727 item vectors inserted.\n",
      "Inserted 50000 / 70727 business mappings.\n",
      "Total 70727 business mappings inserted.\n",
      "Inserted 50000 / 99812 user cluster mappings.\n",
      "Total 99812 user cluster mappings inserted.\n"
     ]
    }
   ],
   "source": [
    "# insert_user_item_cluster(user_cluster, cluster_business, conn)\n",
    "insert_cluster_item(cluster_business, conn)\n",
    "insert_item_vectors(item_similarity_sparse, business_mapping, conn)\n",
    "insert_mappings(business_mapping, conn)\n",
    "insert_user_cluster_mapping(df_cluster, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fc01b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection when done\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f9bcda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(db_path)\n",
    "optimize_db(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2681aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the test data label as 1\n",
    "pos = 3.9\n",
    "test_data_grouped = test_data.groupby('cluster')['business_id'].apply(list).reset_index()\n",
    "# test_data_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69acd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve user-business mappings\n",
    "# def retrieve_business_mapping(conn):\n",
    "#     cursor = conn.cursor()\n",
    "#     cursor.execute('''SELECT business_id, business_idx FROM business_mapping''')\n",
    "#     business_mapping = {row[0]: row[1] for row in cursor.fetchall()}\n",
    "#     return business_mapping\n",
    "\n",
    "# fake_business_mapping = retrieve_business_mapping(conn)\n",
    "# get_top_k_similar_businesses(\"23qa5SsahSsVhqAVmX6aow\", fake_business_mapping, conn, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ebd8ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = simulate_recommendations(test_data_grouped, business_mapping, conn, k=500, num_users=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "976ac018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metric:\n",
      "   Accuracy  Precision  Recall  F1 Score  F-beta Score  Mean Reciprocal Rank\n",
      "0    0.6042     0.4893  0.1177    0.1898        0.1388                0.0496\n",
      "\n",
      "Confusion Matrix:\n",
      "   True Positive  True Negative  False Positive  False Negative\n",
      "0            275           3310             287            2061\n",
      "\n",
      "Background Statistics:\n",
      "   Total Positive  Total Negative  Total    Ratio\n",
      "0            2336            3597   5933  0.39373\n"
     ]
    }
   ],
   "source": [
    "true_positive, true_negative, false_positive, false_negative, total, total_positive, ranks = check_retrieval_recommendations(results, test_data, test_data_grouped, pos)\n",
    "evaluation_metric, confusion, background_stats = compute_evaluation_metric(true_positive, true_negative, false_positive, false_negative, total, total_positive, ranks)\n",
    "print(\"Evaluation Metric:\")\n",
    "print(evaluation_metric)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion)\n",
    "print(\"\\nBackground Statistics:\")\n",
    "print(background_stats)\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content-recommendation-0SgTkEMC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
