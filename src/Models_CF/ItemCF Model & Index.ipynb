{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-base Collaborative Filtering - Model & Index\n",
    "This notebook demonstrates how to build a Item-based collaborative filtering model using Yelp dataset. You can adjust the model to add more features or change the hyperparameters to improve the model performance. The index is built and stored in the `yelp_ItemCF.db` file.\n",
    "\n",
    "#### Pre-requisites\n",
    "1. Have the processed Yelp dataset in the `../../data/processed_data/yelp_data` folder.\n",
    "2. Have the virtual environment setup and used for the notebook.\n",
    "\n",
    "#### Move to Production\n",
    "1. Copy the `yelp_ItemCF.db` file to the `../../data/processed_data` folder.\n",
    "2. Update the `ItemCF.py` file in the `../backend/models` folder if there is changes in retrieval process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sparse_dot_topn import sp_matmul_topn\n",
    "from geopy.distance import geodesic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the database folder path and file names\n",
    "db_folder = '../../data/processed_data/yelp_data/'\n",
    "db_files = ['yelp_business_data.db', 'yelp_review_data.db']\n",
    "db_paths = [db_folder + db_file for db_file in db_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the databases and load data\n",
    "def load_data_from_db():\n",
    "    data = {}\n",
    "    \n",
    "    # Open connections and read tables\n",
    "    conns = [sqlite3.connect(db_path) for db_path in db_paths]\n",
    "    try:\n",
    "        # Load tables from the databases\n",
    "        data['business'] = pd.read_sql_query(\"SELECT * FROM business_details\", conns[0])\n",
    "        data['categories'] = pd.read_sql_query(\"SELECT * FROM business_categories\", conns[0])\n",
    "        data['review'] = pd.read_sql_query(\"SELECT * FROM review_data\", conns[1])\n",
    "    finally:\n",
    "        # Close all database connections\n",
    "        for conn in conns:\n",
    "            conn.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 78059 rows from business table.\n",
      "Loaded 360656 rows from categories table.\n",
      "Loaded 980418 rows from review table.\n"
     ]
    }
   ],
   "source": [
    "# Load data into a dictionary\n",
    "yelp_data = load_data_from_db()\n",
    "\n",
    "# Check loaded data\n",
    "for table, df in yelp_data.items():\n",
    "    print(f\"Loaded {len(df)} rows from {table} table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = yelp_data[\"business\"]\n",
    "df_review = yelp_data[\"review\"]\n",
    "\n",
    "df_concat = df_business.merge(df_review, on='business_id', how='outer', suffixes=('_business', '_review'))\n",
    "df_concat[\"timestamp\"] = pd.to_datetime(df_concat[\"date\"]).astype(int) // 10**9\n",
    "\n",
    "user_business = df_concat[[\"user_id\", \"business_id\", \"stars_review\", \"timestamp\", \"latitude\", \"longitude\", \"city\", \"state\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars_review</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>razUB7ciYZluvxWM6shmtw</td>\n",
       "      <td>--30_8IhuyMHbSOcNWd6DQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1342650622</td>\n",
       "      <td>40.255362</td>\n",
       "      <td>-75.088399</td>\n",
       "      <td>Jamison</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3YhG4h4Ok654iVfqdmkuRg</td>\n",
       "      <td>--7PUidqRWpRSpXebiyxTg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1443362006</td>\n",
       "      <td>53.554659</td>\n",
       "      <td>-113.493040</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VyC2fG4dcMG07nrxh4jLnw</td>\n",
       "      <td>--7PUidqRWpRSpXebiyxTg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1505578181</td>\n",
       "      <td>53.554659</td>\n",
       "      <td>-113.493040</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q5jOFJYhIsN8ouJ1rnsLQQ</td>\n",
       "      <td>--7PUidqRWpRSpXebiyxTg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1407445516</td>\n",
       "      <td>53.554659</td>\n",
       "      <td>-113.493040</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gdcRlubKDmslUYFPHUp1Cg</td>\n",
       "      <td>--8IbOsAAxjKRoYsBFL-PA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1434420633</td>\n",
       "      <td>30.006341</td>\n",
       "      <td>-90.074523</td>\n",
       "      <td>Gentilly</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985727</th>\n",
       "      <td>TkwnhxZfy7AFW1cEIn5u1A</td>\n",
       "      <td>zznJox6-nmXlGYNWgTDwQQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1366231576</td>\n",
       "      <td>27.990058</td>\n",
       "      <td>-82.730226</td>\n",
       "      <td>Clearwater</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985728</th>\n",
       "      <td>weuxfeOxeGs8InkBS1ivbQ</td>\n",
       "      <td>zznJox6-nmXlGYNWgTDwQQ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1573929847</td>\n",
       "      <td>27.990058</td>\n",
       "      <td>-82.730226</td>\n",
       "      <td>Clearwater</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985729</th>\n",
       "      <td>Gix3hMYtxiiQd4Pg626GfQ</td>\n",
       "      <td>zznJox6-nmXlGYNWgTDwQQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1525717667</td>\n",
       "      <td>27.990058</td>\n",
       "      <td>-82.730226</td>\n",
       "      <td>Clearwater</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985730</th>\n",
       "      <td>rB1vREB0x_uynI0ADMs2iA</td>\n",
       "      <td>zztOG2cKm87I6Iw_tleZsQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1622678754</td>\n",
       "      <td>40.092606</td>\n",
       "      <td>-75.393004</td>\n",
       "      <td>King of Prussia</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985731</th>\n",
       "      <td>7UEjHw0g1Wm13Q-MngsdUQ</td>\n",
       "      <td>zztOG2cKm87I6Iw_tleZsQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1584460459</td>\n",
       "      <td>40.092606</td>\n",
       "      <td>-75.393004</td>\n",
       "      <td>King of Prussia</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985732 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id             business_id  stars_review  \\\n",
       "0       razUB7ciYZluvxWM6shmtw  --30_8IhuyMHbSOcNWd6DQ           5.0   \n",
       "1       3YhG4h4Ok654iVfqdmkuRg  --7PUidqRWpRSpXebiyxTg           2.0   \n",
       "2       VyC2fG4dcMG07nrxh4jLnw  --7PUidqRWpRSpXebiyxTg           1.0   \n",
       "3       Q5jOFJYhIsN8ouJ1rnsLQQ  --7PUidqRWpRSpXebiyxTg           1.0   \n",
       "4       gdcRlubKDmslUYFPHUp1Cg  --8IbOsAAxjKRoYsBFL-PA           2.0   \n",
       "...                        ...                     ...           ...   \n",
       "985727  TkwnhxZfy7AFW1cEIn5u1A  zznJox6-nmXlGYNWgTDwQQ           4.0   \n",
       "985728  weuxfeOxeGs8InkBS1ivbQ  zznJox6-nmXlGYNWgTDwQQ           3.0   \n",
       "985729  Gix3hMYtxiiQd4Pg626GfQ  zznJox6-nmXlGYNWgTDwQQ           1.0   \n",
       "985730  rB1vREB0x_uynI0ADMs2iA  zztOG2cKm87I6Iw_tleZsQ           5.0   \n",
       "985731  7UEjHw0g1Wm13Q-MngsdUQ  zztOG2cKm87I6Iw_tleZsQ           5.0   \n",
       "\n",
       "         timestamp   latitude   longitude             city state  \n",
       "0       1342650622  40.255362  -75.088399          Jamison    PA  \n",
       "1       1443362006  53.554659 -113.493040         Edmonton    AB  \n",
       "2       1505578181  53.554659 -113.493040         Edmonton    AB  \n",
       "3       1407445516  53.554659 -113.493040         Edmonton    AB  \n",
       "4       1434420633  30.006341  -90.074523         Gentilly    LA  \n",
       "...            ...        ...         ...              ...   ...  \n",
       "985727  1366231576  27.990058  -82.730226       Clearwater    FL  \n",
       "985728  1573929847  27.990058  -82.730226       Clearwater    FL  \n",
       "985729  1525717667  27.990058  -82.730226       Clearwater    FL  \n",
       "985730  1622678754  40.092606  -75.393004  King of Prussia    PA  \n",
       "985731  1584460459  40.092606  -75.393004  King of Prussia    PA  \n",
       "\n",
       "[985732 rows x 8 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cathy\\AppData\\Local\\Temp\\ipykernel_22120\\3609669763.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_business[\"time_weight\"] = np.exp(-LAMBDA * (current_timestamp - user_business[\"timestamp\"]))\n",
      "C:\\Users\\cathy\\AppData\\Local\\Temp\\ipykernel_22120\\3609669763.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_business[\"weighted_stars\"] = user_business[\"stars_review\"] * user_business[\"time_weight\"]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Define decay factor (tune this)\n",
    "LAMBDA = 0.000000001  # Adjust this based on how fast old reviews should decay\n",
    "\n",
    "# Get the current timestamp\n",
    "current_timestamp = int(time.time())\n",
    "\n",
    "# Compute time-based weight\n",
    "user_business[\"time_weight\"] = np.exp(-LAMBDA * (current_timestamp - user_business[\"timestamp\"]))\n",
    "\n",
    "# Apply weight to ratings\n",
    "user_business[\"weighted_stars\"] = user_business[\"stars_review\"] * user_business[\"time_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         3.363498\n",
       "1         1.487954\n",
       "2         0.791735\n",
       "3         0.717730\n",
       "4         1.474709\n",
       "            ...   \n",
       "985727    2.755004\n",
       "985728    2.543231\n",
       "985729    0.807842\n",
       "985730    4.450470\n",
       "985731    4.283590\n",
       "Name: weighted_stars, Length: 985732, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_business[\"weighted_stars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cathy\\AppData\\Local\\Temp\\ipykernel_22120\\2176412460.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_business[\"time_weight\"] = np.exp(-LAMBDA * (current_timestamp - user_business[\"timestamp\"]))\n",
      "C:\\Users\\cathy\\AppData\\Local\\Temp\\ipykernel_22120\\2176412460.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_business[\"weighted_stars\"] = user_business[\"stars_review\"] * user_business[\"time_weight\"]\n"
     ]
    }
   ],
   "source": [
    "### ----- REGIONAL SIMILARITY ADJUSTMENT -----\n",
    "def region_similarity(biz1, biz2):\n",
    "    city1, state1 = df_concat.loc[df_concat[\"business_id\"] == biz1, [\"city\", \"state\"]].values[0]\n",
    "    city2, state2 = df_concat.loc[df_concat[\"business_id\"] == biz2, [\"city\", \"state\"]].values[0]\n",
    "    \n",
    "    if city1 == city2:\n",
    "        return 1.2  # Boost for same city\n",
    "    elif state1 == state2:\n",
    "        return 1.1  # Small boost for same state\n",
    "    return 1  # No boost otherwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cathy\\AppData\\Local\\Temp\\ipykernel_22120\\188421845.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_business['user_idx'] = user_business['user_id'].map(user_mapping)\n",
      "C:\\Users\\cathy\\AppData\\Local\\Temp\\ipykernel_22120\\188421845.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_business['business_idx'] = user_business['business_id'].map(business_mapping)\n"
     ]
    }
   ],
   "source": [
    "# Create user and business index mappings\n",
    "user_mapping = {user: idx for idx, user in enumerate(user_business['user_id'].unique())}\n",
    "business_mapping = {biz: idx for idx, biz in enumerate(user_business['business_id'].unique())}\n",
    "\n",
    "# Map user_id and business_id to numerical indices\n",
    "user_business['user_idx'] = user_business['user_id'].map(user_mapping)\n",
    "user_business['business_idx'] = user_business['business_id'].map(business_mapping)\n",
    "\n",
    "# Creating the sparse user-item interaction matrix using weighted_stars\n",
    "user_item_sparse = csr_matrix(\n",
    "    (user_business['weighted_stars'], (user_business['user_idx'], user_business['business_idx'])),\n",
    "    shape=(len(user_mapping), len(business_mapping))\n",
    ")\n",
    "\n",
    "# Replace NaN values in the sparse matrix\n",
    "user_item_sparse.data = np.nan_to_num(user_item_sparse.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute inverse mapping to avoid slow lookups\n",
    "inv_business_mapping = {v: k for k, v in business_mapping.items()}\n",
    "\n",
    "# Convert business IDs to arrays for fast lookups\n",
    "business_ids = np.array(list(business_mapping.keys()))\n",
    "\n",
    "def apply_region_weights(C, business_ids, region_similarity):\n",
    "    \"\"\"Applies only regional similarity weighting to a sparse similarity matrix.\"\"\"\n",
    "    \n",
    "    row_indices = np.repeat(np.arange(C.shape[0]), np.diff(C.indptr))  # Row indices\n",
    "    col_indices = C.indices  # Column indices (similar businesses)\n",
    "\n",
    "    # Get actual business IDs for the matching pairs\n",
    "    biz1_ids = business_ids[row_indices]  \n",
    "    biz2_ids = business_ids[col_indices]  \n",
    "\n",
    "    # Compute region weights for all stored values\n",
    "    reg_weights = np.array([region_similarity(b1, b2) for b1, b2 in zip(biz1_ids, biz2_ids)])\n",
    "\n",
    "    # Apply weights directly to the similarity matrix\n",
    "    C.data *= reg_weights  # Only applying regional similarity\n",
    "\n",
    "    return C\n",
    "\n",
    "# Optimized sparse cosine similarity function with regional weights only\n",
    "def sparse_cosine_similarity_topn(A, top_n, threshold=0):\n",
    "    \"\"\"Computes top-N sparse cosine similarity with regional similarity adjustment.\"\"\"\n",
    "    \n",
    "    C = sp_matmul_topn(A.T, A.T, top_n=top_n, threshold=threshold, n_threads=4, sort=True)\n",
    "\n",
    "    # Apply only regional similarity first\n",
    "    C = apply_region_weights(C, business_ids, region_similarity)\n",
    "\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Compute optimized sparse cosine similarity matrix\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m item_similarity_sparse \u001b[38;5;241m=\u001b[39m \u001b[43msparse_cosine_similarity_topn\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_item_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[53], line 32\u001b[0m, in \u001b[0;36msparse_cosine_similarity_topn\u001b[1;34m(A, top_n, threshold)\u001b[0m\n\u001b[0;32m     29\u001b[0m C \u001b[38;5;241m=\u001b[39m sp_matmul_topn(A\u001b[38;5;241m.\u001b[39mT, A\u001b[38;5;241m.\u001b[39mT, top_n\u001b[38;5;241m=\u001b[39mtop_n, threshold\u001b[38;5;241m=\u001b[39mthreshold, n_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Apply only regional similarity first\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[43mapply_region_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbusiness_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion_similarity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m C\n",
      "Cell \u001b[1;32mIn[53], line 18\u001b[0m, in \u001b[0;36mapply_region_weights\u001b[1;34m(C, business_ids, region_similarity)\u001b[0m\n\u001b[0;32m     15\u001b[0m biz2_ids \u001b[38;5;241m=\u001b[39m business_ids[col_indices]  \n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Compute region weights for all stored values\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m reg_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mregion_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbiz1_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbiz2_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Apply weights directly to the similarity matrix\u001b[39;00m\n\u001b[0;32m     21\u001b[0m C\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m reg_weights  \u001b[38;5;66;03m# Only applying regional similarity\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[53], line 18\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     15\u001b[0m biz2_ids \u001b[38;5;241m=\u001b[39m business_ids[col_indices]  \n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Compute region weights for all stored values\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m reg_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mregion_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b1, b2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(biz1_ids, biz2_ids)])\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Apply weights directly to the similarity matrix\u001b[39;00m\n\u001b[0;32m     21\u001b[0m C\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m reg_weights  \u001b[38;5;66;03m# Only applying regional similarity\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[45], line 28\u001b[0m, in \u001b[0;36mregion_similarity\u001b[1;34m(biz1, biz2)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mregion_similarity\u001b[39m(biz1, biz2):\n\u001b[1;32m---> 28\u001b[0m     city1, state1 \u001b[38;5;241m=\u001b[39m df_concat\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdf_concat\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbusiness_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbiz1\u001b[49m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     29\u001b[0m     city2, state2 \u001b[38;5;241m=\u001b[39m df_concat\u001b[38;5;241m.\u001b[39mloc[df_concat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbusiness_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m biz2, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m city1 \u001b[38;5;241m==\u001b[39m city2:\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.virtualenvs\\content-recommendation-mCG3KVaj\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.virtualenvs\\content-recommendation-mCG3KVaj\\Lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.virtualenvs\\content-recommendation-mCG3KVaj\\Lib\\site-packages\\pandas\\core\\series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.virtualenvs\\content-recommendation-mCG3KVaj\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.virtualenvs\\content-recommendation-mCG3KVaj\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:130\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mscalar_compare(x\u001b[38;5;241m.\u001b[39mravel(), y, op)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute optimized sparse cosine similarity matrix\n",
    "item_similarity_sparse = sparse_cosine_similarity_topn(user_item_sparse, top_n=50, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# function without distance and region adjustments\n",
    "# Function to calculate sparse cosine similarity with top N items\n",
    "def sparse_cosine_similarity_topn(A, top_n, threshold=0):\n",
    "    # A is the sparse matrix (user-item matrix)\n",
    "    # ntop is the number of top similar items you want\n",
    "    # lower_bound is the minimum similarity score to consider\n",
    "\n",
    "    # # Compute the top N cosine similarities in a sparse format\n",
    "    \n",
    "    C = sp_matmul_topn(A.T, A.T, top_n=top_n, threshold=threshold, n_threads=4, sort=True)\n",
    "\n",
    "    return C\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_db(conn):\n",
    "    \"\"\"Apply SQLite performance optimizations.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.executescript('''\n",
    "        PRAGMA synchronous = OFF;\n",
    "        PRAGMA journal_mode = MEMORY;\n",
    "        PRAGMA temp_store = MEMORY;\n",
    "        PRAGMA cache_size = 1000000;\n",
    "    ''')\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def insert_user_item(user_business, conn, batch_size=50000):\n",
    "    \"\"\"Optimized batch insert for user-item interactions.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('BEGIN TRANSACTION')\n",
    "\n",
    "    total_records = len(user_business)\n",
    "    data = user_business[['user_id', 'business_id', 'stars_review']].values.tolist()\n",
    "\n",
    "    for i in range(0, total_records, batch_size):\n",
    "        batch = data[i:i + batch_size]\n",
    "        cursor.executemany('''INSERT OR IGNORE INTO user_item_index (user_id, business_id, stars_review)\n",
    "                              VALUES (?, ?, ?)''', batch)\n",
    "\n",
    "        if i % (batch_size * 5) == 0:  # Commit every 5 batches\n",
    "            conn.commit()\n",
    "            print(f\"Inserted {i + len(batch)} / {total_records} user-item records.\")\n",
    "\n",
    "    conn.commit()  # Final commit\n",
    "    print(f\"Total {total_records} user-item records inserted.\")\n",
    "\n",
    "\n",
    "def insert_item_vectors(item_similarity_sparse, business_mapping, conn, batch_size=5000, progress_interval=50000):\n",
    "    \"\"\"Optimized batch insert for item similarity vectors.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('BEGIN TRANSACTION')\n",
    "\n",
    "    total_inserted = 0\n",
    "    batch = []\n",
    "    business_keys = list(business_mapping.keys())  # Convert keys to list for faster indexing\n",
    "\n",
    "    for row_idx in range(item_similarity_sparse.shape[0]):\n",
    "        row_vector = item_similarity_sparse.getrow(row_idx)\n",
    "        row_indices = row_vector.indices\n",
    "        row_data = row_vector.data\n",
    "\n",
    "        serialized_row = pickle.dumps((row_indices, row_data))\n",
    "        item_id = business_keys[row_idx]  # Faster lookup\n",
    "\n",
    "        batch.append((item_id, serialized_row))\n",
    "\n",
    "        if len(batch) >= batch_size:\n",
    "            cursor.executemany('''INSERT OR REPLACE INTO item_item_similarity (item_id, similarity_vector)\n",
    "                                  VALUES (?, ?)''', batch)\n",
    "            total_inserted += len(batch)\n",
    "\n",
    "            if total_inserted % progress_interval == 0:\n",
    "                print(f\"Inserted {total_inserted} item vectors...\")\n",
    "\n",
    "            batch = []\n",
    "\n",
    "    if batch:  # Insert remaining records\n",
    "        cursor.executemany('''INSERT OR REPLACE INTO item_item_similarity (item_id, similarity_vector)\n",
    "                              VALUES (?, ?)''', batch)\n",
    "        total_inserted += len(batch)\n",
    "\n",
    "    conn.commit()\n",
    "    print(f\"Total {total_inserted} item vectors inserted.\")\n",
    "\n",
    "\n",
    "def insert_mappings(business_mapping, conn, batch_size=50000):\n",
    "    \"\"\"Optimized batch insert for business mappings.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('BEGIN TRANSACTION')\n",
    "\n",
    "    data = list(business_mapping.items())\n",
    "    total_records = len(data)\n",
    "\n",
    "    for i in range(0, total_records, batch_size):\n",
    "        batch = data[i:i + batch_size]\n",
    "        cursor.executemany('''INSERT OR REPLACE INTO business_mapping (business_id, business_idx)\n",
    "                              VALUES (?, ?)''', batch)\n",
    "\n",
    "        if i % (batch_size * 5) == 0:  # Commit every 5 batches\n",
    "            conn.commit()\n",
    "            print(f\"Inserted {i + len(batch)} / {total_records} business mappings.\")\n",
    "\n",
    "    conn.commit()\n",
    "    print(f\"Total {total_records} business mappings inserted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQLite (this will create a file-based database)\n",
    "db_path = './yelp_ItemCF.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "optimize_db(conn)\n",
    "\n",
    "# Create tables for user-item and item-item indexes\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS user_item_index (\n",
    "    user_id TEXT,\n",
    "    business_id TEXT,\n",
    "    stars_review REAL,\n",
    "    PRIMARY KEY (user_id, business_id)\n",
    ")''')\n",
    "\n",
    "cursor.execute('''CREATE INDEX idx_user_item ON user_item_index(user_id, business_id)''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS item_item_similarity (\n",
    "    item_id TEXT PRIMARY KEY,\n",
    "    similarity_vector BLOB\n",
    ")''')\n",
    "\n",
    "cursor.execute('''CREATE INDEX idx_item_similarity ON item_item_similarity(item_id)''')\n",
    "\n",
    "# cursor.execute('''CREATE TABLE IF NOT EXISTS user_mapping (\n",
    "#     user_id TEXT PRIMARY KEY,\n",
    "#     user_idx INTEGER\n",
    "# )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS business_mapping (\n",
    "    business_id TEXT PRIMARY KEY,\n",
    "    business_idx INTEGER\n",
    ")''')\n",
    "\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 50000 / 985732 user-item records.\n",
      "Inserted 300000 / 985732 user-item records.\n",
      "Inserted 550000 / 985732 user-item records.\n",
      "Inserted 800000 / 985732 user-item records.\n",
      "Total 985732 user-item records inserted.\n",
      "Inserted 50000 item vectors...\n",
      "Total 78059 item vectors inserted.\n",
      "Inserted 50000 / 78059 business mappings.\n",
      "Total 78059 business mappings inserted.\n"
     ]
    }
   ],
   "source": [
    "insert_user_item(user_business, conn)\n",
    "insert_item_vectors(item_similarity_sparse, business_mapping, conn)\n",
    "insert_mappings(business_mapping, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection when done\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content-recommendation-mCG3KVaj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
