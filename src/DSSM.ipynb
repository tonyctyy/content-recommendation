{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras import layers, Model, backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the database folder path and file names\n",
    "db_folder = '../data/processed_data/yelp_data/'\n",
    "db_files = ['yelp_business_data.db', 'yelp_review_data.db', 'yelp_user_data.db', 'yelp_tip_data.db']\n",
    "db_paths = [db_folder + db_file for db_file in db_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the databases and load data\n",
    "def load_data_from_db():\n",
    "    data = {}\n",
    "    \n",
    "    # Open connections and read tables\n",
    "    conns = [sqlite3.connect(db_path) for db_path in db_paths]\n",
    "    try:\n",
    "        # Load tables from the databases\n",
    "        data['business'] = pd.read_sql_query(\"SELECT * FROM business_details\", conns[0])\n",
    "        data['categories'] = pd.read_sql_query(\"SELECT * FROM business_categories\", conns[0])\n",
    "        data['review'] = pd.read_sql_query(\"SELECT * FROM review_data\", conns[1])\n",
    "        data['user'] = pd.read_sql_query(\"SELECT * FROM user_data\", conns[2])\n",
    "        data['tip'] = pd.read_sql_query(\"SELECT * FROM tip_data\", conns[3])\n",
    "        \n",
    "    finally:\n",
    "        # Close all database connections\n",
    "        for conn in conns:\n",
    "            conn.close()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 78059 rows from business table.\n",
      "Loaded 360656 rows from categories table.\n",
      "Loaded 980418 rows from review table.\n",
      "Loaded 229447 rows from user table.\n",
      "Loaded 173085 rows from tip table.\n"
     ]
    }
   ],
   "source": [
    "# Load data into a dictionary\n",
    "yelp_data = load_data_from_db()\n",
    "\n",
    "# Check loaded data\n",
    "for table, df in yelp_data.items():\n",
    "    print(f\"Loaded {len(df)} rows from {table} table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data\n",
    "# for table, df in yelp_data.items():\n",
    "#     print(f\"{table}:\\n\")\n",
    "#     print(df.head(), \"\\n\")\n",
    "#     print(df.info(), \"\\n\")\n",
    "\n",
    "# Preprocess user data\n",
    "user_df = yelp_data['user']\n",
    "user_df['yelping_since'] = pd.to_datetime(user_df['yelping_since'])\n",
    "\n",
    "# Example: Extract numerical features for embedding\n",
    "user_features = user_df[['review_count', 'useful', 'funny', 'cool', 'fans', 'average_stars']].fillna(0)\n",
    "\n",
    "# Preprocess business data\n",
    "business_df = yelp_data['business']\n",
    "business_df['is_open'] = business_df['is_open'].fillna(0).astype(int)\n",
    "\n",
    "# Example: Extract numerical features\n",
    "business_features = business_df[['stars', 'review_count', 'latitude', 'longitude']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode user_id and business_id\n",
    "user_id_encoder = LabelEncoder()\n",
    "business_id_encoder = LabelEncoder()\n",
    "\n",
    "user_df['user_id_encoded'] = user_id_encoder.fit_transform(user_df['user_id'])\n",
    "business_df['business_id_encoded'] = business_id_encoder.fit_transform(business_df['business_id'])\n",
    "\n",
    "# Save number of unique users and businesses for embedding input_dim\n",
    "num_users = user_df['user_id_encoded'].max() + 1\n",
    "num_businesses = business_df['business_id_encoded'].max() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: Encode 'city' as a discrete feature for businesses\n",
    "# business_city_encoder = LabelEncoder()\n",
    "# business_df['city_encoded'] = business_city_encoder.fit_transform(business_df['city'])\n",
    "\n",
    "# # Save number of unique cities for embedding input_dim\n",
    "# num_cities = business_df['city_encoded'].max() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize user continuous features\n",
    "user_continuous_features = user_df[['review_count', 'useful', 'funny', 'cool', 'fans', 'average_stars']].fillna(0)\n",
    "user_scaler = StandardScaler()\n",
    "user_continuous_features_scaled = user_scaler.fit_transform(user_continuous_features)\n",
    "\n",
    "# Standardize business continuous features\n",
    "business_continuous_features = business_df[['stars', 'review_count', 'latitude', 'longitude']].fillna(0)\n",
    "business_scaler = StandardScaler()\n",
    "business_continuous_features_scaled = business_scaler.fit_transform(business_continuous_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_layer(input_dim, output_dim, name):\n",
    "    \"\"\"Reusable function to create an embedding layer.\"\"\"\n",
    "    return layers.Embedding(input_dim=input_dim, output_dim=output_dim, name=f\"{name}_embedding\")\n",
    "\n",
    "# Create embedding layers\n",
    "user_id_embedding = create_embedding_layer(num_users, 16, \"user_id\")\n",
    "business_id_embedding = create_embedding_layer(num_businesses, 16, \"business_id\")\n",
    "# city_embedding = create_embedding_layer(num_cities, 8, \"city\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_tower(num_users, continuous_dim):\n",
    "    # Inputs\n",
    "    user_id_input = layers.Input(shape=(1,), name=\"user_id\")\n",
    "    user_continuous_input = layers.Input(shape=(continuous_dim,), name=\"user_continuous\")\n",
    "\n",
    "    # Embedding\n",
    "    user_id_embedded = user_id_embedding(user_id_input)\n",
    "    user_id_embedded = layers.Flatten()(user_id_embedded)\n",
    "\n",
    "    # Combine\n",
    "    concat = layers.Concatenate()([user_id_embedded, user_continuous_input])\n",
    "    x = layers.Dense(64, activation='relu')(concat)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    user_embedding = layers.Dense(16, activation=None, name=\"user_embedding\")(x)\n",
    "\n",
    "    return Model([user_id_input, user_continuous_input], user_embedding, name=\"UserTower\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_tower(num_businesses, continuous_dim):\n",
    "    # Inputs\n",
    "    business_id_input = layers.Input(shape=(1,), name=\"business_id\")\n",
    "    business_continuous_input = layers.Input(shape=(continuous_dim,), name=\"business_continuous\")\n",
    "\n",
    "    # Embedding\n",
    "    business_id_embedded = business_id_embedding(business_id_input)\n",
    "    business_id_embedded = layers.Flatten()(business_id_embedded)\n",
    "\n",
    "    # Combine\n",
    "    concat = layers.Concatenate()([business_id_embedded, business_continuous_input])\n",
    "    x = layers.Dense(64, activation='relu')(concat)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    business_embedding = layers.Dense(16, activation=None, name=\"business_embedding\")(x)\n",
    "\n",
    "    return Model([business_id_input, business_continuous_input], business_embedding, name=\"ItemTower\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate towers\n",
    "user_model = user_tower(num_users, user_continuous_features_scaled.shape[1])\n",
    "item_model = item_tower(num_businesses, business_continuous_features_scaled.shape[1])\n",
    "\n",
    "# Inputs\n",
    "user_inputs = [user_df['user_id_encoded'], user_continuous_features_scaled]\n",
    "business_inputs = [business_df['business_id_encoded'], business_continuous_features_scaled]\n",
    "\n",
    "# Get embeddings\n",
    "user_emb = user_model(user_inputs)\n",
    "business_emb = item_model(business_inputs)\n",
    "\n",
    "# Dot product model\n",
    "dot_product = tf.keras.layers.Dot(axes=-1)([user_model.output, item_model.output])\n",
    "model = tf.keras.Model(inputs=[user_model.input, item_model.input], outputs=dot_product)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = yelp_data['review']\n",
    "\n",
    "# Create labels for review data\n",
    "review_df['label'] = (review_df['stars'] >= 4).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(review_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def safe_transform(label_encoder, ids, default=-1):\n",
    "#     \"\"\"Safely transform IDs, assigning a default value to unseen IDs.\"\"\"\n",
    "#     known_ids = set(label_encoder.classes_)\n",
    "#     return [label_encoder.transform([id_])[0] if id_ in known_ids else default for id_ in ids]\n",
    "\n",
    "# # Safely encode IDs for train_df and test_df\n",
    "# train_df['user_id_encoded'] = safe_transform(user_id_encoder, train_df['user_id'])\n",
    "# train_df['business_id_encoded'] = safe_transform(business_id_encoder, train_df['business_id'])\n",
    "\n",
    "# test_df['user_id_encoded'] = safe_transform(user_id_encoder, test_df['user_id'])\n",
    "# test_df['business_id_encoded'] = safe_transform(business_id_encoder, test_df['business_id'])\n",
    "\n",
    "# # Filter out rows where default (-1) was assigned (optional)\n",
    "# train_df = train_df[(train_df['user_id_encoded'] != -1) & (train_df['business_id_encoded'] != -1)]\n",
    "# test_df = test_df[(test_df['user_id_encoded'] != -1) & (test_df['business_id_encoded'] != -1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all encoded user and business IDs\n",
    "known_user_ids = set(user_id_encoder.classes_)\n",
    "known_business_ids = set(business_id_encoder.classes_)\n",
    "\n",
    "# Filter out rows with unseen IDs in train_df\n",
    "train_df = train_df[\n",
    "    train_df['user_id'].isin(known_user_ids) & \n",
    "    train_df['business_id'].isin(known_business_ids)\n",
    "]\n",
    "\n",
    "# Filter out rows with unseen IDs in test_df\n",
    "test_df = test_df[\n",
    "    test_df['user_id'].isin(known_user_ids) & \n",
    "    test_df['business_id'].isin(known_business_ids)\n",
    "]\n",
    "\n",
    "# Encode remaining IDs\n",
    "train_df['user_id_encoded'] = user_id_encoder.transform(train_df['user_id'])\n",
    "train_df['business_id_encoded'] = business_id_encoder.transform(train_df['business_id'])\n",
    "\n",
    "test_df['user_id_encoded'] = user_id_encoder.transform(test_df['user_id'])\n",
    "test_df['business_id_encoded'] = business_id_encoder.transform(test_df['business_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training inputs\n",
    "train_user_inputs = [\n",
    "    train_df['user_id_encoded'].values,\n",
    "    user_scaler.transform(user_df.loc[train_df['user_id_encoded'], user_continuous_features.columns])\n",
    "]\n",
    "train_item_inputs = [\n",
    "    train_df['business_id_encoded'].values,\n",
    "    business_scaler.transform(business_df.loc[train_df['business_id_encoded'], business_continuous_features.columns])\n",
    "]\n",
    "\n",
    "# Testing inputs\n",
    "test_user_inputs = [\n",
    "    test_df['user_id_encoded'].values,\n",
    "    user_scaler.transform(user_df.loc[test_df['user_id_encoded'], user_continuous_features.columns])\n",
    "]\n",
    "test_item_inputs = [\n",
    "    test_df['business_id_encoded'].values,\n",
    "    business_scaler.transform(business_df.loc[test_df['business_id_encoded'], business_continuous_features.columns])\n",
    "]\n",
    "\n",
    "# Labels\n",
    "train_labels = train_df['label'].values\n",
    "test_labels = test_df['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yueny\\.virtualenvs\\content-recommendation-0SgTkEMC\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: [['user_id', 'user_continuous'], ['business_id', 'business_continuous']]. Received: the structure of inputs=(('*', '*'), ('*', '*'))\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12256/12256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 14ms/step - accuracy: 0.6515 - loss: 0.7345 - val_accuracy: 0.7209 - val_loss: 0.5724\n",
      "Epoch 2/10\n",
      "\u001b[1m12256/12256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 15ms/step - accuracy: 0.7499 - loss: 0.5562 - val_accuracy: 0.7226 - val_loss: 0.5792\n",
      "Epoch 3/10\n",
      "\u001b[1m12256/12256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 15ms/step - accuracy: 0.7783 - loss: 0.5033 - val_accuracy: 0.7203 - val_loss: 0.5949\n",
      "Epoch 4/10\n",
      "\u001b[1m12256/12256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 16ms/step - accuracy: 0.7950 - loss: 0.4855 - val_accuracy: 0.7175 - val_loss: 0.5672\n",
      "Epoch 5/10\n",
      "\u001b[1m12256/12256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 15ms/step - accuracy: 0.8067 - loss: 0.4651 - val_accuracy: 0.7155 - val_loss: 0.6242\n",
      "Epoch 6/10\n",
      "\u001b[1m12256/12256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 16ms/step - accuracy: 0.8056 - loss: 0.4761 - val_accuracy: 0.4032 - val_loss: 0.8711\n",
      "Epoch 7/10\n",
      "\u001b[1m12256/12256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 15ms/step - accuracy: 0.7901 - loss: 0.5292 - val_accuracy: 0.7136 - val_loss: 0.6234\n",
      "Epoch 8/10\n",
      "\u001b[1m12256/12256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 15ms/step - accuracy: 0.8044 - loss: 0.4855 - val_accuracy: 0.6675 - val_loss: 0.7743\n",
      "Epoch 9/10\n",
      "\u001b[1m12256/12256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 14ms/step - accuracy: 0.8173 - loss: 0.4871 - val_accuracy: 0.7139 - val_loss: 0.6807\n",
      "Epoch 10/10\n",
      "\u001b[1m12256/12256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 14ms/step - accuracy: 0.8119 - loss: 0.4771 - val_accuracy: 0.7027 - val_loss: 0.7487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x225dc2b5210>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    [train_user_inputs, train_item_inputs],\n",
    "    train_labels,\n",
    "    validation_data=([test_user_inputs, test_item_inputs], test_labels),\n",
    "    epochs=10,\n",
    "    batch_size=64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6128/6128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step\n",
      "Test Accuracy: 0.7026580445115359\n"
     ]
    }
   ],
   "source": [
    "# Predict similarity on test data\n",
    "test_predictions = model.predict([test_user_inputs, test_item_inputs])\n",
    "\n",
    "# Convert cosine similarity to binary predictions\n",
    "predicted_labels = (test_predictions > 0.5).astype(int)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model\n",
    "model.save('user_item_similarity_model.h5')\n",
    "\n",
    "# Save user tower\n",
    "user_model.save('user_tower_model.h5')\n",
    "\n",
    "# Save item tower\n",
    "item_model.save('item_tower_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save label encoders for user_id and business_id\n",
    "joblib.dump(user_id_encoder, 'user_id_encoder.pkl')\n",
    "joblib.dump(business_id_encoder, 'business_id_encoder.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content-recommendation-0SgTkEMC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
