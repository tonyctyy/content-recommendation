{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Recommendation Baseline,\n",
    "    This notebook implements a Random Recommendation baseline model for the Yelp dataset. It recommends a random set of businesses to each user and evaluates the performance using retrieval metrics.\n",
    "    \n",
    "#### Pre-requisites,\n",
    "- The Yelp dataset is loaded from the processed data folder (`../../data/processed_data/yelp_data/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the database folder path and file names\n",
    "db_folder = '../../data/processed_data/yelp_data/'\n",
    "db_files = ['yelp_business_data.db', 'yelp_review_data.db']\n",
    "db_paths = [db_folder + db_file for db_file in db_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the databases and load data\n",
    "def load_data_from_db():\n",
    "    data = {}\n",
    "    conns = [sqlite3.connect(db_path) for db_path in db_paths]\n",
    "    try:\n",
    "        data['business'] = pd.read_sql_query(\"SELECT * FROM business_details\", conns[0])\n",
    "        data['review'] = pd.read_sql_query(\"SELECT * FROM review_data\", conns[1])\n",
    "    finally:\n",
    "        for conn in conns:\n",
    "            conn.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 78059 rows from business table.\n",
      "Loaded 980418 rows from review table.\n"
     ]
    }
   ],
   "source": [
    "yelp_data = load_data_from_db()\n",
    "\n",
    "for table, df in yelp_data.items():\n",
    "    print(f\"Loaded {len(df)} rows from {table} table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = yelp_data[\"business\"]\n",
    "df_review = yelp_data[\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = df_business.merge(df_review, on='business_id', how='outer', suffixes=('_business', '_review'))\n",
    "user_business = df_concat[[\"user_id\", \"business_id\", \"stars_review\"]]\n",
    "\n",
    "all_business_ids = user_business['business_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(user_business, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_random_interests(user_id, k=10, all_business_ids=all_business_ids):\n",
    "    recommended_businesses = np.random.choice(all_business_ids, size=k, replace=False)\n",
    "    scores = np.random.uniform(0, 1, size=k)\n",
    "    return list(zip(recommended_businesses, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = test_data[test_data['stars_review'] >= 4]\n",
    "negative_reviews = test_data[test_data['stars_review'] <= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews: 136473\n",
      "Number of negative reviews: 32929\n",
      "Total number of reviews: 197147\n",
      "Ratio of positive to negative reviews: 4.14\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of positive reviews: {len(positive_reviews)}\")\n",
    "print(f\"Number of negative reviews: {len(negative_reviews)}\")\n",
    "print(f\"Total number of reviews: {len(test_data)}\")\n",
    "print(f\"Ratio of positive to negative reviews: {len(positive_reviews) / len(negative_reviews):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_grouped = test_data.groupby('user_id')['business_id'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = {}\n",
    "k_recommendations = 300\n",
    "max_users = min(1000, len(test_data_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_users):\n",
    "    user_id = test_data_grouped['user_id'].iloc[i]\n",
    "    recommendation = predict_random_interests(user_id, k=k_recommendations)\n",
    "    business_ids, scores = zip(*recommendation)\n",
    "    recommendations[user_id] = (list(business_ids), list(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_recommendations(recommendations, test_data_grouped, pos=4):\n",
    "    total = 0\n",
    "    total_positive = 0\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    ranks = []\n",
    "    for i, row in test_data_grouped.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        business_ids = row['business_id']\n",
    "        rank = 0\n",
    "        if user_id in recommendations:\n",
    "            recommended_businesses = recommendations[user_id][0]\n",
    "            for business_id in business_ids:\n",
    "                star_rating = test_data[(test_data['user_id'] == user_id) & \n",
    "                                       (test_data['business_id'] == business_id)]['stars_review'].values[0]\n",
    "                if star_rating >= pos:\n",
    "                    total_positive += 1\n",
    "                if business_id in recommended_businesses:\n",
    "                    if star_rating >= pos:\n",
    "                        true_positive += 1\n",
    "                    else:\n",
    "                        false_positive += 1\n",
    "                    rank = recommended_businesses.index(business_id) + 1\n",
    "                else:\n",
    "                    if star_rating < pos:\n",
    "                        true_negative += 1\n",
    "                    else:\n",
    "                        false_negative += 1\n",
    "            total += len(business_ids)\n",
    "        ranks.append(rank)\n",
    "    return true_positive, true_negative, false_positive, false_negative, total, total_positive, ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive, true_negative, false_positive, false_negative, total, total_positive, ranks = check_recommendations(recommendations, test_data_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metric, confusion_matrix, background_stats = compute_evaluation_metric(true_positive, true_negative, false_positive, false_negative, total, total_positive, ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Statistics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Positive</th>\n",
       "      <th>Total Negative</th>\n",
       "      <th>Total</th>\n",
       "      <th>Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1821</td>\n",
       "      <td>813</td>\n",
       "      <td>2634</td>\n",
       "      <td>0.691344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Positive  Total Negative  Total     Ratio\n",
       "0            1821             813   2634  0.691344"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F-beta Score</th>\n",
       "      <th>Mean Reciprocal Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3102</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision  Recall  F1 Score  F-beta Score  Mean Reciprocal Rank\n",
       "0    0.3102        0.7  0.0038    0.0076        0.0048                0.0164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Positive</th>\n",
       "      <th>True Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>False Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>810</td>\n",
       "      <td>3</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   True Positive  True Negative  False Positive  False Negative\n",
       "0              7            810               3            1814"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Testing Data Statistics\")\n",
    "display(background_stats)\n",
    "\n",
    "print(\"Evaluation Metrics\")\n",
    "display(evaluation_metric)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content-recommendation-HkY1UuQH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
