{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Structured Semantic Model - Retrieval Evaluation\n",
    "This notebook is used to simulate the performance of the of the DSSM model in a retrieval setting. \n",
    "\n",
    "#### Pre-requisites\n",
    "- The model is trained and the index is created in the notebooks `DSSM Model.ipynb` and `DSSM Index (Faiss).ipynb`.\n",
    "- All required files are saved in the `Saved_Triplet_Hinge_Loss` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 78059 rows from business_details table.\n",
      "Loaded 360656 rows from business_categories table.\n",
      "Loaded 980418 rows from review table.\n",
      "Loaded 229447 rows from user table.\n",
      "Loaded 173085 rows from tip table.\n"
     ]
    }
   ],
   "source": [
    "from general_program import *\n",
    "import faiss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yueny\\.virtualenvs\\content-recommendation-0SgTkEMC\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_folder_path = \"Saved_Triplet_Hinge_Loss/\"\n",
    "\n",
    "user_model, item_model, user_id_encoder, business_id_encoder, categories_encoder, business_geohash_encoder, user_scaler, business_scaler = load_saved_models(save_folder_path=save_folder_path)\n",
    "\n",
    "# Load the Faiss index from the file\n",
    "faiss_index = faiss.read_index(save_folder_path+ \"faiss_index.bin\")\n",
    "\n",
    "# Load the business_ids from the file\n",
    "business_ids = np.load(save_folder_path + \"business_ids.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df, business_df, review_df, user_continuous_features_scaled, business_continuous_features_scaled, num_users, num_businesses, num_categories, num_geohashes = prepare_data(user_df, business_df, review_df, categories_df, user_id_encoder, business_id_encoder, categories_encoder, business_geohash_encoder, user_scaler, business_scaler, use_stage='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews: 135929\n",
      "Number of negative reviews: 60155\n",
      "Total number of reviews: 196084\n",
      "Ratio of positive to negative reviews: 2.26\n"
     ]
    }
   ],
   "source": [
    "# Split review_df into train and test sets\n",
    "train_data, test_data = train_test_split(review_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the test set into positive and negative samples\n",
    "positive_reviews = test_data[test_data['stars'] >= 4]\n",
    "negative_reviews = test_data[test_data['stars'] < 4]\n",
    "\n",
    "print(f\"Number of positive reviews: {len(positive_reviews)}\")\n",
    "print(f\"Number of negative reviews: {len(negative_reviews)}\")\n",
    "print(f\"Total number of reviews: {len(test_data)}\")\n",
    "print(f\"Ratio of positive to negative reviews: {len(positive_reviews) / len(negative_reviews):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_test_data(positive_reviews, negative_reviews):\n",
    "    # Ensure positive reviews can be downsampled without error\n",
    "    if len(positive_reviews) >= len(negative_reviews):\n",
    "        positive_reviews_downsampled = positive_reviews.sample(n=len(negative_reviews), random_state=42)\n",
    "    else:\n",
    "        print(\"Warning: More negative reviews than positive ones. Keeping all positives.\")\n",
    "        positive_reviews_downsampled = positive_reviews  # No downsampling if already balanced or reversed\n",
    "\n",
    "    # Combine and shuffle using NumPy for better performance\n",
    "    balanced_test_data = pd.concat([positive_reviews_downsampled, negative_reviews], ignore_index=True)\n",
    "    balanced_test_data = balanced_test_data.iloc[np.random.permutation(len(balanced_test_data))].reset_index(drop=True)\n",
    "\n",
    "    # Print final stats\n",
    "    print(f\"Number of positive reviews: {len(positive_reviews_downsampled)}\")\n",
    "    print(f\"Number of negative reviews: {len(negative_reviews)}\")\n",
    "    print(f\"Total number of reviews: {len(balanced_test_data)}\")\n",
    "    print(f\"Ratio of positive to negative reviews: {len(positive_reviews_downsampled) / len(negative_reviews):.2f}\")\n",
    "\n",
    "    return balanced_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews: 60155\n",
      "Number of negative reviews: 60155\n",
      "Total number of reviews: 120310\n",
      "Ratio of positive to negative reviews: 1.00\n"
     ]
    }
   ],
   "source": [
    "# balance the test data, comment this line to use the original test data\n",
    "test_data = balance_test_data(positive_reviews, negative_reviews)\n",
    "\n",
    "# group the test data by user_id and get the business_id\n",
    "test_data_grouped = test_data.groupby('user_id')['business_id'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_top_k(user_id, user_model, faiss_index, business_ids, k=100):\n",
    "    # Check if the user_id is in the user_id_encoder\n",
    "    if user_id not in user_id_encoder.classes_:\n",
    "        # raise ValueError(\"User ID is not in the encoder\")\n",
    "        user_id = \"default_user\"\n",
    "\n",
    "    # Encode user_id and get continuous features\n",
    "    user_id_encoded = user_id_encoder.transform([user_id])[0]\n",
    "    user_cont_features = user_scaler.transform(\n",
    "        user_continuous_features_scaled.loc[[user_id_encoded]].values\n",
    "    )\n",
    "\n",
    "    # Predict the user's embedding\n",
    "    # user_embedding = user_model.predict([np.array([user_id_encoded]), user_cont_features], verbose=0)\n",
    "\n",
    "    user_embedding = user_model.predict([user_id_encoded.reshape(1, -1), user_cont_features], verbose=0)\n",
    "    user_embedding_normalized = normalize(user_embedding, axis=1)\n",
    "\n",
    "    # Perform ANN search using Faiss\n",
    "    distances, indices = faiss_index.search(user_embedding_normalized, k)\n",
    "\n",
    "    # Return top-k businesses and distances\n",
    "    top_k_business_ids = business_ids[indices.flatten()]\n",
    "\n",
    "    # valid_indices = indices[indices != -1].flatten()\n",
    "    # top_k_business_ids = business_ids[valid_indices]\n",
    "\n",
    "    return top_k_business_ids, distances.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query top-k businesses for each user\n",
    "top_k = 5000\n",
    "target_users = 1000\n",
    "\n",
    "top_k_businesses = {}\n",
    "i = 0\n",
    "business_ids = business_continuous_features_scaled.index.values\n",
    "for user_id in test_data_grouped['user_id']:\n",
    "    if user_id not in user_id_encoder.classes_:\n",
    "        user_id = \"default_user\"\n",
    "    # print(f\"It is now handling {user_id}\")\n",
    "    encoded_business, distances = query_top_k(user_id, user_model, faiss_index, business_ids, k=top_k)\n",
    "    \n",
    "    # Decode the business IDs\n",
    "    business_ids_decoded = business_id_encoder.inverse_transform(encoded_business)\n",
    "    top_k_businesses[user_id] = business_ids_decoded\n",
    "    i += 1\n",
    "    if i >= target_users:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_recommendations(recommendations, test_data_grouped, pos=4):\n",
    "    # Create a dictionary for fast lookup: {(user_id, business_id): stars}\n",
    "    test_data_lookup = {\n",
    "        (row['user_id'], row['business_id']): row['stars']\n",
    "        for _, row in test_data.iterrows()\n",
    "    }\n",
    "    \n",
    "    total = 0\n",
    "    total_positive = 0\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    ranks = []\n",
    "\n",
    "    for _, row in test_data_grouped.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        business_ids = row['business_id']  # List of businesses the user reviewed\n",
    "        rank = None  # Default to None\n",
    "\n",
    "        if user_id in recommendations:\n",
    "            recommended_businesses = recommendations[user_id]\n",
    "\n",
    "            for business_id in business_ids:\n",
    "                star_rating = test_data_lookup.get((user_id, business_id), None)\n",
    "\n",
    "                if star_rating is None:\n",
    "                    continue  # Skip if no rating is found (safety check)\n",
    "\n",
    "                if star_rating >= pos:\n",
    "                    total_positive += 1\n",
    "\n",
    "                if business_id in recommended_businesses:\n",
    "                    if star_rating >= pos:\n",
    "                        true_positive += 1\n",
    "                    else:\n",
    "                        false_positive += 1\n",
    "                    \n",
    "                    # Get rank safely\n",
    "                    try:\n",
    "                        rank = np.where(recommended_businesses == business_id)[0][0] + 1\n",
    "                    except IndexError:\n",
    "                        rank = None  # Business ID not found in recommendations\n",
    "                else:\n",
    "                    if star_rating < pos:\n",
    "                        true_negative += 1\n",
    "                    else:\n",
    "                        false_negative += 1\n",
    "            \n",
    "            total += len(business_ids)\n",
    "        \n",
    "        ranks.append(rank)\n",
    "\n",
    "    return true_positive, true_negative, false_positive, false_negative, total, total_positive, ranks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive, true_negative, false_positive, false_negative, total, total_positive, ranks = check_recommendations(top_k_businesses, test_data_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Statistics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Positive</th>\n",
       "      <th>Total Negative</th>\n",
       "      <th>Total</th>\n",
       "      <th>Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1047</td>\n",
       "      <td>1084</td>\n",
       "      <td>2131</td>\n",
       "      <td>0.491319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Positive  Total Negative  Total     Ratio\n",
       "0            1047            1084   2131  0.491319"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F-beta Score</th>\n",
       "      <th>Mean Reciprocal Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.5918</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>0.1003</td>\n",
       "      <td>0.0064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision  Recall  F1 Score  F-beta Score  Mean Reciprocal Rank\n",
       "0    0.5214     0.5918  0.0831    0.1457        0.1003                0.0064"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Positive</th>\n",
       "      <th>True Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>False Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>1024</td>\n",
       "      <td>60</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   True Positive  True Negative  False Positive  False Negative\n",
       "0             87           1024              60             960"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = (true_positive + true_negative) / float(total) if total > 0 else 0\n",
    "precision = true_positive / float(true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "recall = true_positive / float(total_positive) if total_positive > 0 else 0\n",
    "f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Mean Reciprocal Rank (MRR) - safer handling\n",
    "mean_reciprocal_rank = np.mean([1 / rank for rank in ranks if rank is not None and rank > 0]) if ranks else 0\n",
    "\n",
    "# Weighted Fβ-score\n",
    "beta = 2\n",
    "f_beta = (1 + beta**2) * precision * recall / (beta**2 * precision + recall) if (beta**2 * precision + recall) > 0 else 0\n",
    "\n",
    "# Compute dataset statistics\n",
    "total_negative = total - total_positive if total > 0 else 0\n",
    "background_stats = pd.DataFrame({\n",
    "    'Total Positive': [total_positive],\n",
    "    'Total Negative': [total_negative],\n",
    "    'Total': [total],\n",
    "    'Ratio': [total_positive / float(total) if total > 0 else 0],\n",
    "})\n",
    "\n",
    "print(\"Testing Data Statistics\")\n",
    "display(background_stats)\n",
    "\n",
    "# Evaluation Metrics\n",
    "evaluation_metric = pd.DataFrame({\n",
    "    'Accuracy': [accuracy],\n",
    "    'Precision': [precision],\n",
    "    'Recall': [recall],\n",
    "    'F1 Score': [f1_score],\n",
    "    'F-beta Score': [f_beta],\n",
    "    'Mean Reciprocal Rank': [mean_reciprocal_rank],\n",
    "}).apply(lambda x: round(x, 4))\n",
    "\n",
    "print(\"Evaluation Metrics\")\n",
    "display(evaluation_metric)\n",
    "\n",
    "# Confusion Matrix\n",
    "confusion_matrix = pd.DataFrame({\n",
    "    'True Positive': [true_positive],\n",
    "    'True Negative': [true_negative],\n",
    "    'False Positive': [false_positive],\n",
    "    'False Negative': [false_negative]\n",
    "})\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_path = '../Retrieval Result/Retrieval.db'\n",
    "# conn = sqlite3.connect(db_path)\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# # Create a lookup for fast access to star ratings from the test data:\n",
    "# # This dictionary maps (user_id, business_id) to the star rating.\n",
    "# test_data_lookup = {\n",
    "#     (row['user_id'], row['business_id']): row['stars']\n",
    "#     for _, row in test_data.iterrows()\n",
    "# }\n",
    "\n",
    "# # Prepare bulk records for insertion into SQLite.\n",
    "# # Format: (model, user_id, business_id, real_label)\n",
    "# # Here we assume a positive review (real_label = 1) if stars >= 4, else negative (real_label = 0).\n",
    "# bulk_records = []\n",
    "# model_name = \"DSSM\"  # You can change this if needed\n",
    "\n",
    "# for user_id, recommended_businesses in top_k_businesses.items():\n",
    "#     for business_id in recommended_businesses:\n",
    "#         # Check the star rating from the test data lookup\n",
    "#         star_rating = test_data_lookup.get((user_id, business_id))\n",
    "#         # Define the real label: 1 if rating is available and >= 4, otherwise 0.\n",
    "#         real_label = 1 if star_rating is not None and star_rating >= 4 else 0\n",
    "#         bulk_records.append((model_name, user_id, business_id, real_label))\n",
    "\n",
    "# # Example: Now perform a bulk insert using SQLite's executemany.\n",
    "# # Make sure your 'recommendations' table has a UNIQUE constraint on (model, user_id, business_id) if needed.\n",
    "# cursor.executemany(\"\"\"\n",
    "#     INSERT OR IGNORE INTO recommendations (model, user_id, business_id, real_label)\n",
    "#     VALUES (?, ?, ?, ?)\n",
    "# \"\"\", bulk_records)\n",
    "# conn.commit()\n",
    "\n",
    "# # Close the connection\n",
    "# conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content-recommendation-0SgTkEMC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
