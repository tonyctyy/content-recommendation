{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Structured Semantic Model - Triplet Hinge Loss\n",
    "This notebook is used to train the Deep Structured Semantic Model (DSSM) using the Yelp dataset. The DSSM model is used to predict user and business interest based on the user and business features. The model is trained using the Triplet Hinge Loss as the loss function according the the paper from Facebook. The goal is to separate the positive and negative samples by a margin, so that the positive samples are closer to the anchor than the negative samples. \n",
    "\n",
    "#### Pre-requisites\n",
    "1. Have the processed Yelp dataset in the `../../data/processed_data/yelp_data` folder.\n",
    "2. Have the virtual environment setup and used for the notebook.\n",
    "\n",
    "#### Output\n",
    "1. `user_model.keras` - The trained user model for retrieval. \n",
    "2. `user_id_encoder.pkl` - The label encoder for the user id.\n",
    "3. `user_scaler.pkl` - The scaler for the user features.\n",
    "4. `business_model.keras` - The trained business model for retrieval.\n",
    "5. `business_id_encoder.pkl` - The label encoder for the business id.\n",
    "6. `categories_encoder.pkl` - The label encoder for the business categories.\n",
    "7. `business_scaler.pkl` - The scaler for the business features.\n",
    "    \n",
    "#### Move to Production\n",
    "1. Before moving to production, the model should be indexed in the `DSSM Index (Faiss).ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 78059 rows from business_details table.\n",
      "Loaded 360656 rows from business_categories table.\n",
      "Loaded 980418 rows from review table.\n",
      "Loaded 229447 rows from user table.\n",
      "Loaded 173085 rows from tip table.\n"
     ]
    }
   ],
   "source": [
    "from general_program import *\n",
    "from tensorflow.keras.layers import Dot, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_encoder = LabelEncoder()\n",
    "user_id_encoder = LabelEncoder()\n",
    "business_id_encoder = LabelEncoder()\n",
    "business_geohash_encoder = LabelEncoder()\n",
    "\n",
    "user_scaler = StandardScaler()\n",
    "business_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yueny\\.virtualenvs\\content-recommendation-0SgTkEMC\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\yueny\\.virtualenvs\\content-recommendation-0SgTkEMC\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Code\\FYP\\content-recommendation\\src\\Models_DSSM\\general_program.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy_positive_df['label'] = 1\n",
      "c:\\Code\\FYP\\content-recommendation\\src\\Models_DSSM\\general_program.py:140: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  positive_df = pd.concat([positive_df, easy_positive_df])\n",
      "c:\\Code\\FYP\\content-recommendation\\src\\Models_DSSM\\general_program.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy_negative_df['label'] = 0\n",
      "c:\\Code\\FYP\\content-recommendation\\src\\Models_DSSM\\general_program.py:145: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  negative_df = pd.concat([negative_df, easy_negative_df])\n",
      "c:\\Code\\FYP\\content-recommendation\\src\\Models_DSSM\\general_program.py:152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_positive_df['label'] = 1\n",
      "c:\\Code\\FYP\\content-recommendation\\src\\Models_DSSM\\general_program.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_positive_df['difficulty'] = 1\n",
      "c:\\Code\\FYP\\content-recommendation\\src\\Models_DSSM\\general_program.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_negative_df['label'] = 0\n",
      "c:\\Code\\FYP\\content-recommendation\\src\\Models_DSSM\\general_program.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard_negative_df['difficulty'] = 1\n"
     ]
    }
   ],
   "source": [
    "user_df, business_df, review_df, label_df, user_continuous_features_scaled, business_continuous_features_scaled, num_users, num_businesses, num_categories, num_geohashes = prepare_data(user_df, business_df, review_df, categories_df, user_id_encoder, business_id_encoder, categories_encoder, business_geohash_encoder, user_scaler, business_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_continuous_features_scaled = user_continuous_features_scaled.set_index(user_df['user_id_encoded'].values)\n",
    "business_continuous_features_scaled = business_continuous_features_scaled.set_index(business_df['business_id_encoded'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_layer(input_dim, output_dim, name):\n",
    "    return layers.Embedding(\n",
    "        input_dim=input_dim,\n",
    "        output_dim=output_dim,\n",
    "        name=f\"{name}_embedding\",\n",
    "        # embeddings_regularizer=regularizers.l2(1e-4)  # L2 regularization\n",
    "    )\n",
    "\n",
    "# Create embedding layers\n",
    "user_id_embedding = create_embedding_layer(num_users, 16, \"user_id\")\n",
    "business_id_embedding = create_embedding_layer(num_businesses, 16, \"business_id\")\n",
    "category_embedding = create_embedding_layer(num_categories, 16, \"category\")\n",
    "business_geohash_embedding = create_embedding_layer(num_geohashes, 16, \"geohash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_tower(continuous_dim):\n",
    "    # Inputs\n",
    "    user_id_input = layers.Input(shape=(1,), name=\"user_id\")\n",
    "    user_continuous_input = layers.Input(shape=(continuous_dim,), name=\"user_continuous\")\n",
    "\n",
    "    # Embedding\n",
    "    user_id_embedded = user_id_embedding(user_id_input)\n",
    "    user_id_embedded = layers.Flatten()(user_id_embedded)\n",
    "\n",
    "    # Combine\n",
    "    concat = layers.Concatenate()([user_id_embedded, user_continuous_input])\n",
    "    x = layers.Dense(64, activation='relu')(concat)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    # x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(concat)\n",
    "    # x = layers.Dropout(0.15)(x)  # Drop 30% of neurons randomly\n",
    "    # x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    # x = layers.Dropout(0.15)(x)  # Drop 30% of neurons randomly\n",
    "    user_embedding = layers.Dense(16, activation=None, name=\"user_embedding\")(x)\n",
    "\n",
    "    return Model([user_id_input, user_continuous_input], user_embedding, name=\"UserTower\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_tower(continuous_dim):\n",
    "    # Inputs\n",
    "    business_id_input = layers.Input(shape=(1,), name=\"business_id\")\n",
    "    business_continuous_input = layers.Input(shape=(continuous_dim,), name=\"business_continuous\")\n",
    "    # category_input = layers.Input(shape=(None,), dtype=\"int32\", name=\"category_indices\")  # Variable-length input\n",
    "    geohash_input = layers.Input(shape=(1,), name=\"geohash\")\n",
    "\n",
    "    # Embedding\n",
    "    business_id_embedded = business_id_embedding(business_id_input)\n",
    "    business_id_embedded = layers.Flatten()(business_id_embedded)\n",
    "\n",
    "    # category_embeddings = category_embedding(category_input)\n",
    "    # aggregated_category_embedding = CategoryPoolingLayer(name=\"category_pooling\")(category_embeddings)\n",
    "\n",
    "    geohash_embedding = business_geohash_embedding(geohash_input)\n",
    "    geohash_embedding = layers.Flatten()(geohash_embedding)\n",
    "\n",
    "    # Combine\n",
    "    concat = layers.Concatenate()([business_id_embedded,\n",
    "                                    # aggregated_category_embedding, \n",
    "                                    geohash_embedding, business_continuous_input])\n",
    "\n",
    "    # x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(concat)\n",
    "    # x = layers.Dropout(0.15)(x)  # Drop 30% of neurons randomly\n",
    "    # x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    # x = layers.Dropout(0.15)(x)  # Drop 30% of neurons randomly\n",
    "    x = layers.Dense(64, activation='relu')(concat)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    business_embedding = layers.Dense(16, activation=None, name=\"business_embedding\")(x)\n",
    "\n",
    "    return Model([business_id_input, \n",
    "                #   category_input,\n",
    "                    geohash_input,\n",
    "                    business_continuous_input],\n",
    "                    business_embedding, name=\"ItemTower\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split label_df into train and test sets\n",
    "train_df, test_df = train_test_split(label_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"binary_dssm_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"binary_dssm_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_id_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_cont_features… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ business_id_input   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ geohash_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ business_cont_feat… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ UserTower           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,675,952</span> │ user_id_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ user_cont_featur… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ItemTower           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275,984</span> │ business_id_inpu… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ geohash_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ business_cont_fe… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ UserTower[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ ItemTower[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ similarity_output   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_id_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_cont_features… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ business_id_input   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ geohash_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ business_cont_feat… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ UserTower           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │  \u001b[38;5;34m3,675,952\u001b[0m │ user_id_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ user_cont_featur… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ItemTower           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │  \u001b[38;5;34m1,275,984\u001b[0m │ business_id_inpu… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ geohash_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ business_cont_fe… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ UserTower[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ ItemTower[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ similarity_output   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dot[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,951,936</span> (18.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,951,936\u001b[0m (18.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,951,936</span> (18.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,951,936\u001b[0m (18.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate towers\n",
    "user_model = user_tower(user_continuous_features_scaled.shape[1])\n",
    "item_model = item_tower(business_continuous_features_scaled.shape[1])\n",
    "\n",
    "# Define inputs for user and business towers\n",
    "user_inputs_model = [Input(shape=(1,), dtype=tf.int32, name=\"user_id_input\"),\n",
    "                     Input(shape=(user_continuous_features_scaled.shape[1],), name=\"user_cont_features_input\")]\n",
    "\n",
    "business_inputs_model = [\n",
    "    Input(shape=(1,), dtype=tf.int32, name=\"business_id_input\"),\n",
    "    Input(shape=(1,), dtype=tf.int32, name=\"geohash_input\"),\n",
    "    Input(shape=(business_continuous_features_scaled.shape[1],), name=\"business_cont_features_input\")\n",
    "]\n",
    "\n",
    "user_embedding = user_model(user_inputs_model)    # Shape: (batch, embedding_dim)\n",
    "business_embedding = item_model(business_inputs_model)  # Shape: (batch, embedding_dim)\n",
    "\n",
    "# Compute similarity via dot product (or cosine similarity if you prefer)\n",
    "# Here we use dot product with normalization to approximate cosine similarity.\n",
    "similarity = Dot(axes=-1, normalize=True)([user_embedding, business_embedding])\n",
    "\n",
    "# Apply a sigmoid to produce a probability output\n",
    "output = Activation('sigmoid', name=\"similarity_output\")(similarity)\n",
    "\n",
    "# Build the binary classification model\n",
    "binary_model = Model(\n",
    "    inputs=user_inputs_model + business_inputs_model,\n",
    "    outputs=output,\n",
    "    name=\"binary_dssm_model\"\n",
    ")\n",
    "\n",
    "binary_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "binary_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids =  np.array(train_df['user_id_encoded'].values, dtype=np.int32)\n",
    "business_ids =  np.array(train_df['business_id_encoded'].values, dtype=np.int32)\n",
    "\n",
    "# Extract values for existing user IDs\n",
    "user_features = user_continuous_features_scaled.loc[user_ids].values\n",
    "\n",
    "# For business continuous features:\n",
    "business_features = business_continuous_features_scaled.loc[business_ids].values\n",
    "\n",
    "business_geohash_map = business_df.set_index('business_id_encoded')['geohash_encoded']\n",
    "\n",
    "# For geohash features, assume you have a similar DataFrame:\n",
    "# Here, I'm assuming business_geohash_map is a DataFrame/Series where the index is business_id_encoded.\n",
    "geohash_features = business_geohash_map.loc[business_ids].values  # Make sure the shapes match\n",
    "\n",
    "labels = train_df['label'].values\n",
    "\n",
    "\n",
    "# Prepare input list for binary_model\n",
    "train_inputs = [\n",
    "    user_ids, user_features,\n",
    "    business_ids, geohash_features, business_features\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12101/12101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 16ms/step - accuracy: 0.8853 - loss: 0.4332 - val_accuracy: 0.7860 - val_loss: 0.5216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2373616a410>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_model.fit(\n",
    "    x=train_inputs,\n",
    "    y=labels,\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder_path = 'Saved_BCE_Loss/'\n",
    "\n",
    "# Save the models\n",
    "user_model.save(save_folder_path + 'user_model.keras')\n",
    "item_model.save(save_folder_path + 'item_model.keras')\n",
    "\n",
    "# Save the label encoders\n",
    "with open(save_folder_path + 'user_id_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(user_id_encoder, f)\n",
    "\n",
    "with open(save_folder_path + 'business_id_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(business_id_encoder, f)\n",
    "\n",
    "with open(save_folder_path + 'categories_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(categories_encoder, f)\n",
    "\n",
    "with open(save_folder_path + 'business_geohash_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(business_geohash_encoder, f)\n",
    "    \n",
    "# Save the scalers\n",
    "with open(save_folder_path + 'user_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(user_scaler, f)\n",
    "\n",
    "with open(save_folder_path + 'business_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(business_scaler, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content-recommendation-0SgTkEMC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
