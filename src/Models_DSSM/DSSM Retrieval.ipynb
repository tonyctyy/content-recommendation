{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Structured Semantic Model - Retrieval\n",
    "This notebook demonstrates how to use the trained DSSM model to retrieve similar users and businesses based on the user and business features. **It can help test if all files are in place and the model is working as expected.**\n",
    "\n",
    "#### Pre-requisites\n",
    "1. Have the processed Yelp dataset in the `../../data/processed_data/yelp_data` folder.\n",
    "2. Have the virtual environment setup and used for the notebook.\n",
    "3. Have all the files in the `./production` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import faiss\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yueny\\.virtualenvs\\content-recommendation-0SgTkEMC\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\yueny\\.virtualenvs\\content-recommendation-0SgTkEMC\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "save_folder_path = \"production/\"\n",
    "\n",
    "# Load business IDs and embeddings\n",
    "business_ids = np.load(save_folder_path + \"business_ids.npy\")\n",
    "\n",
    "# Load the Faiss index from the file\n",
    "faiss_index = faiss.read_index(save_folder_path + \"faiss_index.bin\")\n",
    "\n",
    "# Load the user model\n",
    "user_model = load_model(save_folder_path + 'user_model.keras')\n",
    "\n",
    "# Load the saved label encoders\n",
    "with open(save_folder_path + 'user_id_encoder.pkl', 'rb') as f:\n",
    "    user_id_encoder = pickle.load(f)\n",
    "\n",
    "with open(save_folder_path + 'business_id_encoder.pkl', 'rb') as f:\n",
    "    business_id_encoder = pickle.load(f)\n",
    "\n",
    "# Load the saved scalers\n",
    "with open(save_folder_path + 'user_scaler.pkl', 'rb') as f:\n",
    "    user_scaler = pickle.load(f)\n",
    "\n",
    "# Load the saved user continuous features (temporal solution)\n",
    "with open(save_folder_path + 'user_continuous_features_scaled.pkl', 'rb') as f:\n",
    "    user_continuous_features_scaled = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_top_k(user_id, user_model, faiss_index, business_ids, k=100):\n",
    "    # Check if the user_id is in the user_id_encoder\n",
    "    if user_id not in user_id_encoder.classes_:\n",
    "        raise ValueError(\"User ID is not in the encoder\")\n",
    "\n",
    "    # Encode user_id and get continuous features\n",
    "    user_id_encoded = user_id_encoder.transform([user_id])[0]\n",
    "    user_cont_features = user_scaler.transform(\n",
    "        user_continuous_features_scaled.loc[[user_id_encoded]].values\n",
    "    )\n",
    "\n",
    "    # Predict the user's embedding\n",
    "    user_embedding = user_model.predict([np.array([user_id_encoded]), user_cont_features])\n",
    "    user_embedding_normalized = normalize(user_embedding, axis=1)\n",
    "\n",
    "    # Perform ANN search using Faiss\n",
    "    distances, indices = faiss_index.search(user_embedding_normalized, k)\n",
    "\n",
    "    # Return top-k businesses and distances\n",
    "    top_k_business_ids = business_ids[indices.flatten()]\n",
    "    return top_k_business_ids, distances.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yueny\\.virtualenvs\\content-recommendation-0SgTkEMC\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step\n",
      "               business_id  similarity_score\n",
      "0   -qtgI1xDDSqxtTtPn3ERHw          0.864202\n",
      "1   CeQtgiR1EuGedqwh1uyLQQ          0.861182\n",
      "2   atZ_olNKXOG4rEr6mccN8g          0.858346\n",
      "3   kfW3-LmZlKrXq3RndVXxdg          0.848915\n",
      "4   E8NgBaDyaVPWxmyDvHSP0g          0.848732\n",
      "..                     ...               ...\n",
      "95  qFsh80AAL90tkOc0n98bqg          0.767803\n",
      "96  3CFVBCfjdCvESS1ogBv21A          0.767122\n",
      "97  2Wmvi5-7LS1iw5UkOuLWlw          0.766358\n",
      "98  Qe721w_WLS88SnBcu37ngg          0.766280\n",
      "99  DNMDGalFejExZqwb_YVQnQ          0.765853\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "user_id = \"9HQLEChkam3GMBQn0SmvVw\"  # Replace with an actual user_id\n",
    "top_k_business_ids, scores = query_top_k(user_id, user_model, faiss_index, business_ids, k=100)\n",
    "\n",
    "# Decode business IDs back to their original format\n",
    "decoded_business_ids = business_id_encoder.inverse_transform(top_k_business_ids)\n",
    "result_df = pd.DataFrame({\n",
    "    'business_id': decoded_business_ids,\n",
    "    'similarity_score': scores\n",
    "})\n",
    "\n",
    "print(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content-recommendation-0SgTkEMC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
